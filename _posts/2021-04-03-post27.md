---
title: "Core Audio Overview - What is Core Audio"
toc: true
toc_sticky: true
tags:
  - iOS
  - Core_Audio
categories: "Core_Audio"
---

Core Audio Overview - What is Core Audio 애플 개발자 문서를 번역한 글입니다. [원문](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/WhatisCoreAudio/WhatisCoreAudio.html#//apple_ref/doc/uid/TP40003577-CH3-SW1)은 아카이브되었습니다.

> 영어 실력이 많이 부족합니다ㅠ 수정 제안 환영합니다 🙌

# What is Core Audio?

Core Audio는 iOS 및 OS X의 디지털 오디오 인프라입니다. 여기에는 앱의 오디오 요구를 처리하도록 설계된 소프트웨어 프레임워크 집합이 포함되어 있습니다. Core Audio로 할 수 있는 작업에 대해 알아보려면 이 챕터를 읽으세요.

## iOS와 OS X에서의 Core Audio

Core Audio는 고성능 및 짧은 대기 시간을 위해 iOS와 OS X에 긴밀하게 통합됩니다.

OS X에서, 대부분의 Core Audio 서비스는 Figure 1-1과 같이 HAL(Hardware Abstraction Layer) 위에 계층화됩니다. 오디오 신호는 HAL을 통해 하드웨어에 전달됩니다. 실시간 오디오가 필요한 경우, Core Audio 프레임워크의 Audio Hardware Service를 사용해 HAL에 접근할 수 있습니다. Core MIDI(Musical Instrument Digital Interface) 프레임워크는 MIDI 데이터 및 장치 작업을 위해 유사한 인터페이스를 제공합니다.

Figure 1-1 OS X Core Audio architecture

![Figure 1-1 OS X Core Audio architecture](https://user-images.githubusercontent.com/45457678/113474551-9381ae00-94ab-11eb-910a-de6e509b732b.png)

Audio Toolbox 및 Audio Unit 프레임워크에서 Core Audio 앱 수준 서비스를 찾을 수 있습니다.

- Audio Queue Service를 사용해 오디오를 녹음, 재생, 일시 중지, 반복 및 동기화하세요.
- Audio File, Converter, and Codec Services를 사용해 디스크에서 읽고 쓰고 오디오 데이터 형식 변환을 수행하세요. OS X에서는 사용자 정의 코덱을 만들 수도 있습니다.
- Audio Unit Services and Audio Processing Graph Services(그림에서 "Audio units"로 표시됨)를 사용해 앱에서 오디오 장치(오디오 플러그인) 호스팅하세요. OS X에서는 앱에서 사용하거나 다른 앱에서 사용할 수 있도록 제공하기 위해 커스텀 오디오 장치를 만들 수도 있습니다.
- Music Sequencing Services를 사용해 MIDI 기반 컨트롤 및 음악 데이터를 재생하세요.
- 오디오 및 MIDI 동기화 및 시간 형식 관리를 위해 Core Audio Clock Services를 사용하세요.
- System Sound Services(그림에서 "System sounds"로 표시됨)를 사용해 시스템 사운드 및 사용자 인터페이스 사운드 효과를 재생하세요.

iOS의 Core Audio는 배터리 구동(battery-powered) 모바일 플랫폼에서 사용할 수 있는 컴퓨팅 리소스에 최적화되어 있습니다. 운영체제, 특히 HAL 및 I/O Kit에서 매우 엄격하게 관리해야 하는 서비스용 API는 없습니다. 그러나 iOS에는 OS X에 없는 추가 서비스가 있습니다. 예를 들어, Audio Session Services를 사용해 휴대폰과 iPad으로 작동하는 기기의 컨텍스트에서 앱의 오디오 동작을 관리할 수 있습니다. Figure 1-2는 iOS의 오디오 아키텍처에 대한 고수준의 보기를 제공합니다.

Figure 1-2 iOS Core Audio architecture

![Figure 1-2 iOS Core Audio architecture](https://user-images.githubusercontent.com/45457678/113475452-c4b0ad00-94b0-11eb-8db6-4090cfa4bfeb.png)

## 디지털 오디오 및 선형 PCM에 대한 정보

대부분의 Core Audio 서비스는 가장 일반적인 비압축 디지털 오디오 데이터 형식인 선형 PCM(linear purse-code-modulated) 형식의 오디오를 사용하고 조작합니다. 디지털 오디오 녹음은 아날로그(실제) 오디오 신호의 크기를 일정한 간격(샘플링 속도)으로 측정하고 각 샘플을 숫자 값으로 변환해 PCM 데이터를 만듭니다. 표준 CD(compact disc) 오디오는 해상도 또는 비트 깊이를 구성하는 각 샘플을 묘사하는 16비트 정수와 함께 44.1kHz의 샘플링 속도를 사용합니다. 

- *sample*은 단일 채널에 대한 단일 숫자값입니다.
- *frame*은 동시 발생(time-coincident) 샘플의 집합입니다. 예를 들어, 스테레오 사운드 파일에는 프레임 당 두 개의 샘플이 있습니다. 각각 왼쪽, 오른쪽 채널 용입니다.
- *packet*은 하나 이상의 연속 프레임 모음입니다. 선형 PCM 오디오에서, 패킷은 항상 단일 프레임입니다. 압축 형식에서는, 일반적으로 더 많습니다. 패킷은 주어진 오디오 데이터 형식에 대해 가장 작고 의미있는 프레임 집합을 정의합니다.

선형 PCM 오디오에서, 샘플 값은 나타내는 원래 신호의 진폭에 따라 선형적으로 변합니다. 예를 들어, 표준 CD 오디오의 16비트 정수 샘플은 무음과 최대 레벨 사이에 가능한 65536개의 값을 허용합니다. 한 디지털 값에서 다음 값으로의 진폭 차이는 항상 동일합니다. CoreAudioTypes.h 헤더 파일에 선언된 Core Audio 데이터 구조는 모든 샘플 속도 및 비트 깊이의 선형 PCM을 설명할 수 있습니다. [Audio Data Formats](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW7)에서 이 주제에 대한 세부정보를 확인하세요.

OS X에서, Core Audio는 오디오 데이터가 native-endian, 32비트 부동 소수점, 선형 PCM 형식일 것으로 예상합니다. Audio Converter Services를 사용해 서로 다른 선형 PCM 변종(variants) 간에 오디오 데이터를 변환할 수 있습니다. 또한 이 변환기를 사용하면 선형 PCM과 MP3 및 Apple Lossless와 같은 압축 오디오 형식간의 변환이 가능합니다. OS X의 Core Audio는 대부분의 일반적인 디지털 오디오 형식을 변환하는 코덱을 제공합니다.(MP3로 변환하기 위한 인코더는 제공하지 않음)

iOS는 정수 및 고정 소수점 오디오 데이터를 사용합니다. 그 결과 오디오를 처리할 때 계산 속도가 빨라지고 배터리 소모가 줄어듭니다. iOS는 Converter 오디오 장치를 제공하고 Audio Converter Services의 인터페이스를 포함합니다. iOS 및 OS X 용 소위 *표준이 되는(canonical)* 오디오 데이터 형식에 대한 자세한 내용은 [Canonical Audio Data Formats](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW16)를 참조하세요.

iOS 및 OS X에서 Core Audio는 [iPhone Audio File Formats](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW47) 및 [Supported Audio File and Data Formats in OS X](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/SupportedAudioFormatsMacOSX/SupportedAudioFormatsMacOSX.html#//apple_ref/doc/uid/TP40003577-CH7-SW1)에 설명된대로 오디오 데이터 저장 및 재생을 위한 가장 일반적인 파일 형식을 지원합니다. 

## 오디오 장치

*Audio units*은 오디오 데이터를 처리하는 소프트웨어 플러그인입니다. OS X에서는, 단일 오디오 장치를 무제한의 채널 및 앱에서 동시에 사용할 수 있습니다. iOS는 모바일 플랫폼에서 효율성과 성능에 최적화된 오디오 장치 집합을 제공합니다. iOS 앱에서 사용할 오디오 장치를 개발할 수 있습니다. 커스텀 오디오 장치 코드를 앱에서 정적으로 링크해야하므로, 개발한 오디오 장치는 iOS의 다른 앱에서 사용할 수 없습니다. 

iOS에서 제공되는 오디오 장치에는 사용자 인터페이스가 없습니다. 주요 용도는 앱에서 지연 시간이 짧은 오디오를 제공하는 것입니다. 아이폰 오디오 장치에 대한 자세한 내용은 [Core Audio Plug-ins: Audio Units and Codecs](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/CoreAudioEssentials/CoreAudioEssentials.html#//apple_ref/doc/uid/TP40003577-CH10-SW10)을 참조하세요.

개발하는 맥앱에서 시스템 제공하는 장치 또는 3rd 파티 제공 오디오 장치를 사용할 수 있습니다. 오디오 장치를 제품으로 자체 개발할 수도 있습니다. 사용자는 GarageBand 및 Logic Studio와 같은 앱 뿐만 아니라 다른 많은 오디오 장치 호스팅 앱에서 오디오 장치를 사용할 수 있습니다.

일부 맥 오디오 장치는 백그라운드에서 작동하여 신호 분할 또는 하드웨어 인터페이스와 같은 일반적인 작업을 단순화합니다. 다른 것들은 신호 처리 및 조작을 제공하기 위해 자체 사용자 인터페이스와 함께 화면에 나타납니다. 예를 들어, 이펙터(effect units)는 기타리스트의 distortion box와 같은 실제 장치를 모방할 수 있습니다. 다른 오디오 장치는 프로그래밍 방식 또는 MIDI 입력에 대한 응답으로 신호를 생성합니다.

오디오 장치의 몇 가지 예시는 다음과 같습니다:

- signal processor(예를 들어 high-pass filter, 리버브, 압축기, distortion unit). 이들 각각은 일반적으로 이펙터이며 hardware effects box 또는 outboard signal processor와 유사한방식으로 DSP(Digital Signal Processing)를 수행합니다.
- musical instrument 또는 software synthesizer. *instrument units*(때로는 music devices)라고 하고 일반적으로 MIDI 입력에 응답해 음표를 생성합니다.
- signal source. instrument unit과 달리, 생성기 장치는 MIDI 입력이 아닌 코드를 통해 활성화 됩니다. 예를 들어, 생성기 장치는 사인파를 계산 및 생성하거나 파일 또는 네트워크 스트림에서 데이터를 가져올 수 있습니다.
- 하드웨어 입력 또는 출력에 대한 인터페이스입니다. I/O 장치에 대해 더 자세한 내용은 [The Hardware Abstraction Layer](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/WhatisCoreAudio/WhatisCoreAudio.html#//apple_ref/doc/uid/TP40003577-CH3-SW6) 및 [Interfacing with Hardware](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/ARoadmaptoCommonTasks/ARoadmaptoCommonTasks.html#//apple_ref/doc/uid/TP40003577-CH6-SW12)을 참조하세요.
- format converter. *converter unit*은 두 개의 선형 PCM 변종 간의 데이터를 변환하고, 오디오 스트림을 병합 또는 분할하거나, 시간 및 피치 변경을 수행할 수 있습니다. 
- mixer or panner. *mixer unit*은 오디오 트랙을 결합할 수 있습니다. *panner unit*은 스테레오 또는 3D 패닝 효과를 적용할 수 있습니다.
- 오프라인으로 작동하는 effect unit. 오프라인 effect unit은 너무 프로세서 집약적(processor-intensive)이거나 단순히 실시간으로 불가능한 작업을 수행합니다. 예를 들어, 파일에서 시간 반전을 수행하는 효과는 오프라인으로 적용해야 합니다.

OS X에서는 당신이나 최종 사용자가 필요로 하는 모든 순열(permutation)에서 오디오 장치를 믹스 앤 매치할 수 있습니다. Figure 1-3은 간단한 오디오 장치 체인을 보여줍니다. 외부 MIDI 키보드에서 수신한 컨트롤 데이터를 기반으로 오디오 신호를 생성하는 instrument unit이 있을 때, 생성된 오디오는 effect units을 통과해 bandpass filtering 및 distortion을 적용합니다. 오디오 장치 체인을 오디오 처리 그래프라고 합니다.

Figure 1-3 A simple audio processing graph

![Figure 1-3 A simple audio processing graph](https://user-images.githubusercontent.com/45457678/113479368-ab682a80-94c9-11eb-86e2-087b8186b322.png)

여러 앱에서 사용할 수 있는 DSP 코드를 개발하는 경우, 코드를 오디오 장치로 패키징해야 합니다.

맥 오디오 앱을 개발하는 경우, 오디오 장치 지원을 통해 당신과 당신의 사용자는 기존 오디오 장치(3rd 파티 및 애플 제공 모두) 라이브러리를 활용해 앱의 기능을 확장할 수 있습니다.

OS X에서 오디오 장치를 실험하려면 /Developer/Applications/Audio 경로의 Xcode Tools installation 에서 사용할 수 있는 AU Lab 앱을 참조하세요. AU Lab을 사용하면 오디오 장치를 믹스 앤 매치하여 출력 장치를 통해 오디오 소스에서 신호 체인을 구축할 수 있습니다.

OS X v10.5 및 iOS 2.0과 함께 제공되는 오디오 장치 목록은 [System-Supplied Audio Units in OS X](https://developer.apple.com/library/archive/documentation/MusicAudio/Conceptual/CoreAudioOverview/SystemAudioUnits/SystemAudioUnits.html#//apple_ref/doc/uid/TP40003577-CH8-SW2)를 참조하세요.

## 하드웨어 추상 레이어(HAL)

Core Audio는 HAL(Hardware Abstraction Layer)을 사용해 앱이 하드웨어와 상호작용할 수 있도록 일관되고 예측 가능한 인터페이스를 제공합니다. HAL은 동기화를 단순화하거나 지연 시간을 조정하기 위해 앱에 타이밍 정보를 제공할 수도 있습니다.

대부분의 경우에 당신의 코드는 직접적으로 HAL과 상호작용하지 않습니다. 애플은 다른 오디오 장치에서 하드웨어로 오디오를 전달할 수 있는 특수 오디오 장치(OS X의 경우 AUHAL 장치, iOS의 경우 AURemoteIO 장치)를 제공합니다. 마찬가지로, 하드웨어에서 들어오는 입력은 Figure 1-4에 표시된대로 AUHAL 장치(또는 iOS의 AURemoteIO 장치)를 통해 라우팅되고 후속 오디오 장치에서 사용할 수 있습니다.

Figure 1-4 Hardware input through the HAL and the AUHAL unit

![Figure 1-4 Hardware input through the HAL and the AUHAL unit](https://user-images.githubusercontent.com/45457678/113479973-e4ee6500-94cc-11eb-95bc-913c40422405.png)

AUHAL 장치(또는 AURemoteIO 장치)는 오디오 장치와 하드웨어 간의 오디오 데이터를 변환하는데 필요한 모든 데이터 변환 또는 채널 매핑도 처리합니다.

Mac 관련 뒷내용은 추가 예정입니다 :)